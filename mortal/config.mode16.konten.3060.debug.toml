[control]
version = 4
online = false
decision_head = "value"
policy_temp = 1.0
policy_top_p = 1.0
policy_epsilon = 0.0
state_file = "E:/Mahjong/output/checkpoints/mortal_mode16_konten_3060_debug.pth"
best_state_file = "E:/Mahjong/output/checkpoints/mortal_mode16_konten_3060_debug_best.pth"
tensorboard_dir = "E:/Mahjong/output/tensorboard/mortal_mode16_konten_3060_debug"
device = "cuda:0"
enable_cudnn_benchmark = false
enable_amp = true
enable_compile = false
batch_size = 128
opt_step_every = 4
save_every = 40
test_every = 1000000
submit_every = 400

[test_play]
games = 400
log_dir = "E:/Mahjong/output/test_play_mode16_konten_3060_debug"

[dataset]
globs = [ "E:/Mahjong/output/mode16_konten_4p/mjai_rust/*.json.gz",]
file_index = "E:/Mahjong/output/mode16_konten_4p/file_index_mode16_konten_3060.pth"
file_batch_size = 12
reserve_ratio = 0.05
num_workers = 2
player_names_files = []
num_epochs = 8
enable_augmentation = true
augmented_first = true

[env]
gamma = 1
pts = [ 100.0, 50.0, -5.0, -200.0,]
reward_scale = 0.01
q_target_clip = 4.0

[resnet]
conv_channels = 256
num_blocks = 40

[cql]
min_q_weight = 3.5

[aux]
next_rank_weight = 0.2

[freeze_bn]
mortal = false

[optim]
eps = 1e-8
betas = [ 0.9, 0.999,]
weight_decay = 0.12
max_grad_norm = 0.5

[online]
history_window = 50
enable_compile = false

[1v3]
seed_key = -1
games_per_iter = 2000
iters = 500
log_dir = "E:/Mahjong/output/1v3_mode1"

[grp]
state_file = "E:/Mahjong/output/checkpoints/grp_mode16_konten_3060.pth"

[online_policy]
enabled = false
method = "awac"
freeze_mortal = true
freeze_dqn = true
train_aux = false
actor_lr = 3e-6
actor_weight = 1.0
awac_lambda = 1.0
awac_max_weight = 20.0
entropy_coef = 0.002
bc_coef = 0.05
bc_warmup_steps = 5000

[optim.scheduler]
peak = 0.00015
final = 8e-6
warm_up_steps = 8000
max_steps = 200000

[online.remote]
host = "127.0.0.1"
port = 5000

[online.server]
buffer_dir = "E:/Mahjong/output/online_buffer"
drain_dir = "E:/Mahjong/output/online_drain"
sample_reuse_rate = 0
sample_reuse_threshold = 0
capacity = 1600
force_sequential = false

[1v3.challenger]
device = "cuda:0"
name = "mortal"
state_file = "E:/Mahjong/output/checkpoints/mortal_mode1.pth"
stochastic_latent = false
enable_compile = false
enable_amp = true
enable_rule_based_agari_guard = true

[1v3.champion]
device = "cuda:0"
name = "baseline"
state_file = "E:/Mahjong/output/checkpoints/baseline_mode1.pth"
stochastic_latent = false
enable_compile = false
enable_amp = true
enable_rule_based_agari_guard = true

[1v3.akochan]
enabled = false
dir = "/path/to/akochan"
tactics = "/path/to/tactics.json"

[grp.network]
hidden_size = 64
num_layers = 2

[grp.control]
device = "cuda:0"
enable_cudnn_benchmark = true
tensorboard_dir = "E:/Mahjong/output/tensorboard/grp_mode16_konten_3060"
batch_size = 1024
save_every = 2000
val_steps = 400

[grp.dataset]
train_globs = [ "E:/Mahjong/output/mode16_konten_4p/mjai_rust/*.json.gz",]
val_globs = [ "E:/Mahjong/output/mode16_konten_4p/mjai_rust/*.json.gz",]
file_index = "E:/Mahjong/output/mode16_konten_4p/grp_file_index_mode16_konten_3060.pth"
file_batch_size = 100
num_workers = 4

[grp.optim]
lr = 3e-6

[train_play.default]
games = 800
log_dir = "E:/Mahjong/output/train_play_mode16_konten_3060"
boltzmann_epsilon = 0.005
boltzmann_temp = 0.05
top_p = 1.0
decision_head = "value"
policy_temp = 1.0
policy_top_p = 1.0
policy_epsilon = 0.0
repeats = 1

[baseline.train]
device = "cuda:0"
enable_compile = false
state_file = "E:/Mahjong/MahjongCopilot/models/mortal_mode1_best.pth"

[baseline.test]
device = "cuda:0"
enable_compile = false
state_file = "E:/Mahjong/MahjongCopilot/models/mortal_mode1_best.pth"

